# llvms4protest: Large Language and Vision Models for Protests

## Thanks for being interested in using LLVMs to infer protest in texts and images.

When you use one or two of these models, you agree to cite the following papers:

@article{zhang2023generative,
  title={Generative AI has lowered the barriers to computational social sciences},
  author={Zhang, Yongjun},
  journal={arXiv preprint arXiv:2311.10833},
  year={2023}
}

@article{zhang2023llvms4protest,
  title={LLVMs4Protest: Harnessing the Power of Large Language and Vision Models for Deciphering Protests in the News},
  author={Zhang, Yongjun},
  journal={arXiv preprint arXiv:XXX.XXX},
  year={2023}
}


You also agree that these models are solely used for academic purposes.

You can access all models via this dropbox link:
\url{https://www.dropbox.com/scl/fo/99hkkgfmqan75xmwkh3z2/h?rlkey=upisotxf1mn61y8qrswtjga19&dl=0}
